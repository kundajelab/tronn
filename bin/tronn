#!/usr/bin/env python

"""Main executable for TRoNN
"""

import os
import sys
import subprocess
import argparse
import glob


def parse_args():
    """Setup arguments"""

    parser = argparse.ArgumentParser(description='Run TRoNN')
    subparsers = parser.add_subparsers(dest='subcommand_name')

    # command for preprocessing data
    add_preprocess_parser(subparsers)
    
    # command for training
    add_train_parser(subparsers)

    # command for interpretation
    add_interpret_parser(subparsers)

    # parse args
    args = parser.parse_args()

    return args


def add_model_config(args):
    """Add model configs
    """
    # parse model configs
    model_config = {}
    model_config['name'] = args.model[0]
    for model_arg in args.model[1:]:
        if '=' in model_arg:
            name, value = model_arg.split('=', 1)
            model_config[name] = eval(value)
        else:
            model_config[model_arg] = True
    args.model = model_config

    return 


def add_out_dir_option(parser, default=''):
    """Add an output directory if defined
    """
    parser.add_argument("--out_dir", dest="out_dir", type=str, default=default,
                        help = "If specified all output files will be written to that directory. Default: the current working directory")

    return


def add_preprocess_parser(subparsers):
    """Add data generation function argument parser
    """

    argparser_preprocess = subparsers.add_parser("preprocess", help="Preprocess data to TRoNN formats")

    # group for input files
    group_input = argparser_preprocess.add_argument_group("Input files and folders")
    group_input.add_argument("--species_json", help='json of support files')
    group_input.add_argument("--labels", nargs='+', help='list of label file peak sets (BED/narrowPeak)')

    # group for options
    # TODO add parallel option (to control num threads from here)
    group_opts = argparser_preprocess.add_argument_group("Data generation options")
    group_opts.add_argument("--rc", help='Reverse complement')
    group_opts.add_argument("--univ_neg_num", default=200000, help='number of universal negatives to grab from univ DHS regions')
    
    # group for output files
    group_output = argparser_preprocess.add_argument_group("Output files and folders")
    add_out_dir_option(group_output)
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')

    return


def add_train_parser(subparsers):
    """Add training function argument parser
    """

    argparser_train = subparsers.add_parser("train", help="Train a TRoNN model")
    
    # group for input files
    group_input = argparser_train.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--restore', action='store_true', help='restore from last checkpoint')
    group_input.add_argument('--transfer_dir', help='directory with same model to transfer') #this and the next are the same?
    group_input.add_argument('--tasks', nargs='+', default=[], type=int, help='tasks over which to train multitask model on')
    
    # group for model
    group_model = argparser_train.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')
    
    # group for parameters
    group_params = argparser_train.add_argument_group("Training hyperparameters")
    group_params.add_argument('--epochs', default=20, type=int, help='number of epochs')
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')
    group_params.add_argument('--metric', default='mean_auprc', type=str, help='metric to use for early stopping')
    group_params.add_argument('--patience', default=2, type=int, help='metric to use for early stopping')

    # group for output files
    group_output = argparser_train.add_argument_group("Output files and folders")
    add_out_dir_option(group_output, default='log')
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')

    return


def add_interpret_parser(subparsers):
    """Add interpretation function argument parser
    """
    
    argparser_interpret = subparsers.add_parser("interpret", help="Interpret a TRoNN model")

    # group for input files
    group_input = argparser_interpret.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--model_dir', help='trained model for interpretation')

    # group for model
    group_model = argparser_interpret.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')

    # group for parameters
    group_params = argparser_interpret.add_argument_group("Interpretation hyperparameters")
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')

    # group for annotation files
    group_data = argparser_interpret.add_argument_group("External data files")
    group_data.add_argument('--annotations', help='json file of external data files')

    # group for output files
    group_output = argparser_interpret.add_argument_group("Output files and folders")
    add_out_dir_option(group_output)
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')
    group_output.add_argument('--scratch_dir', help='temporary scratch directory')
    
    return


def track_runs(args):
    """track command and github commit
    """

    # keeps track of restores (or different commands) in folder
    num_restores = len(glob.glob(os.path.join(args.out_dir, 'command')))
    
    # track github commit
    git_repo_path = os.path.dirname(os.path.realpath(__file__))
    os.system('echo -e "commit:" > {1}/command{2}.txt'.format(args.out_dir, num_restores))
    os.system('git -C {0} rev-parse HEAD >> {1}/command{2}.txt'.format(git_repo_path, args.out_dir, num_restores))
    os.system('echo -e "" > {1}/command{2}.txt'.format(args.out_dir, num_restores))
    
    # write out the command
    with open(os.path.join(args.out_dir, 'command%d.txt'%num_restores), 'a') as f:
        f.write(' '.join(sys.argv)+'\n')
    
    return 


def main():
    """Main function for running TRoNN functions"""

    args = parse_args()

    print 'out_dir: %s' % args.out_dir
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)
    track_runs(args)

    subcommand  = args.subcommand_name

    if subcommand == "preprocess":
        from tronn.preprocess import run
        run(args)
    elif subcommand == 'train':
        add_model_config(args)
        print 'model args: %s' % args.model
        from tronn.learning import run
        run(args)
    elif subcommand == 'interpret':
        add_model_config(args)
        print 'model args: %s' % args.model
        from tronn.interpretation import run
        run(args)
        
    return None


if __name__ == '__main__':
    main()
