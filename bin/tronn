#!/usr/bin/env python

"""Main executable for TRoNN
"""

import os
import sys
import subprocess
import argparse
import glob


def parse_args():
    """Setup arguments
    """
    parser = argparse.ArgumentParser(description='Run TRoNN')
    subparsers = parser.add_subparsers(dest='subcommand_name')

    # command for preprocessing data
    add_preprocess_parser(subparsers)
    
    # command for training
    add_train_parser(subparsers)

    # command for interpretation
    add_interpret_parser(subparsers)

    # TODO consider a command for visualizing some example sequences

    # parse args
    args = parser.parse_args()

    return args


def add_model_config(args):
    """Add model configs
    """
    # parse model configs
    model_config = {}
    model_config['name'] = args.model[0]
    for model_arg in args.model[1:]:
        if '=' in model_arg:
            name, value = model_arg.split('=', 1)
            model_config[name] = eval(value)
        else:
            model_config[model_arg] = True
    args.model = model_config

    return 


def add_out_dir_option(parser, default=''):
    """Add an output directory if defined
    """
    parser.add_argument("--out_dir", dest="out_dir", type=str, default=default,
                        help = "If specified all output files will be written to that directory. Default: the current working directory")

    return


def add_preprocess_parser(subparsers):
    """Add data generation function argument parser
    """
    argparser_preprocess = subparsers.add_parser("preprocess", help="Preprocess data to TRoNN formats")

    # group for input files
    group_input = argparser_preprocess.add_argument_group("Input files and folders")
    group_input.add_argument("--annotations_json", help='json of support files')
    group_input.add_argument("--labels", nargs='+', help='list of label file peak sets (BED/narrowPeak)')

    # group for options
    group_opts = argparser_preprocess.add_argument_group("Data generation options")
    group_opts.add_argument("--rc", help='Reverse complement')
    group_opts.add_argument("--univ_neg_num", default=200000, help='number of universal negatives to grab from univ DHS regions')
    group_opts.add_argument("--parallel", default=12, type=int,
                            help='Number of parallel threads to use')
    
    # group for output files
    group_output = argparser_preprocess.add_argument_group("Output files and folders")
    add_out_dir_option(group_output)
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')

    return


def add_train_parser(subparsers):
    """Add training function argument parser
    """
    argparser_train = subparsers.add_parser("train", help="Train a TRoNN model")
    
    # group for input files
    group_input = argparser_train.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--restore', action='store_true', help='restore from last checkpoint')
    group_input.add_argument('--transfer_dir', help='directory with same model to transfer') 
    group_input.add_argument('--tasks', nargs='+', default=[], type=int,
                             help='tasks over which to train multitask model on')
    
    # group for model
    group_model = argparser_train.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')
    
    # group for parameters
    group_params = argparser_train.add_argument_group("Training hyperparameters")
    group_params.add_argument('--epochs', default=20, type=int, help='number of epochs')
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')
    group_params.add_argument('--metric', default='mean_auprc', type=str, help='metric to use for early stopping')
    group_params.add_argument('--patience', default=2, type=int, help='metric to use for early stopping')

    # group for output files
    group_output = argparser_train.add_argument_group("Output files and folders")
    add_out_dir_option(group_output, default='log')
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')

    return


def add_interpret_parser(subparsers):
    """Add interpretation function argument parser
    """
    argparser_interpret = subparsers.add_parser("interpret", help="Interpret a TRoNN model")

    # group for input files
    group_input = argparser_interpret.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--model_dir', help='trained model for interpretation')
    group_input.add_argument('--tasks', nargs='+', default=[], type=int,
                             help='tasks over which to train multitask model on')

    # group for model
    group_model = argparser_interpret.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')

    # group for parameters
    group_params = argparser_interpret.add_argument_group("Interpretation hyperparameters")
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')
    group_params.add_argument('--sample_size', default=220000, type=int,
                              help='number of regions to get importance scores')

    # group for annotation files
    group_data = argparser_interpret.add_argument_group("External data files")
    group_data.add_argument('--annotations', help='json file of external data files')

    # group for output files
    group_output = argparser_interpret.add_argument_group("Output files and folders")
    add_out_dir_option(group_output)
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')
    group_output.add_argument('--scratch_dir', help='temporary scratch directory')
    group_output.add_argument('--plot_importances', action='store_true',
                              help='plot some sample sequences weighted by importance scores')
    
    return


def track_runs(args):
    """track command and github commit
    """
    # keeps track of restores (or different commands) in folder
    num_restores = len(glob.glob('{0}/{1}.command'.format(args.out_dir, args.subcommand_name)))
    logging_file = '{0}/{1}.command_{2}.log'.format(args.out_dir, args.subcommand_name, num_restores)
    
    # track github commit
    git_repo_path = os.path.dirname(os.path.realpath(__file__))
    os.system('echo "commit:" > {0}'.format(logging_file))
    os.system('git -C {0} rev-parse HEAD >> {1}'.format(git_repo_path, logging_file))
    os.system('echo "" >> {0}'.format(logging_file))
    
    # write out the command
    with open(logging_file, 'a') as f:
        f.write(' '.join(sys.argv)+'\n')
    
    return logging_file


def main():
    """Main function for running TRoNN functions"""

    args = parse_args()

    print 'out_dir: %s' % args.out_dir
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)
    logging_file = track_runs(args)

    subcommand  = args.subcommand_name

    if subcommand == "preprocess":
        from tronn.preprocess import run
        run(args)
    elif subcommand == 'train':
        add_model_config(args)
        print 'model args: %s' % args.model
        from tronn.learning import run
        run(args)
    elif subcommand == 'interpret':
        add_model_config(args)
        print 'model args: %s' % args.model
        from tronn.interpret import run
        run(args)
        
    return None


if __name__ == '__main__':
    main()
