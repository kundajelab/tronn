#!/usr/bin/env python

"""Main executable for TRoNN
"""

import os
import sys
import subprocess
import argparse
import glob

#import tensorflow as tf


from tronn.models import models


def parse_args():
    """Setup arguments"""

    parser = argparse.ArgumentParser(description='Run TRoNN')
    subparsers = parser.add_subparsers(dest='subcommand_name')
    
    # command for training
    add_train_parser(subparsers)

    # command for interpretation
    add_interpret_parser(subparsers)

    # parse args
    args = parser.parse_args()

    # configs for model
    add_model_config(args)

    print 'out_dir: %s' % args.out_dir
    print 'model args: %s' % args.model
    
    return args


def add_model_config(args):
    """Add model configs
    """
    # parse model configs
    model_config = {}
    model_config['name'] = args.model[0]
    for model_arg in args.model[1:]:
        if '=' in model_arg:
            name, value = model_arg.split('=', 1)
            model_config[name] = eval(value)
        else:
            model_config[model_arg] = True
    args.model = model_config

    return 


def add_out_dir_option(parser, default=''):
    """Add an output directory if defined
    """
    parser.add_argument("--out_dir", dest="outdir", type=str, default=default,
                        help = "If specified all output files will be written to that directory. Default: the current working directory")


def add_preprocess_parser(subparsers):
    """Add data generation function argument parser
    """


    return


def add_train_parser(subparsers):
    """Add training function argument parser
    """

    argparser_train = subparsers.add_parser("train", help="Train a TRoNN model")
    
    # group for input files
    group_input = argparser_train.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--restore', action='store_true', help='restore from last checkpoint')
    group_input.add_argument('--transfer_dir', help='directory with same model to transfer') #this and the next are the same?
    group_input.add_argument('--tasks', nargs='+', default=[], type=int, help='tasks over which to train multitask model on')
    
    # group for model
    group_model = argparser_train.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')
    
    # group for parameters
    group_params = argparser_train.add_argument_group("Training hyperparameters")
    group_params.add_argument('--epochs', default=20, type=int, help='number of epochs')
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')
    group_params.add_argument('--metric', default='mean_auprc', type=str, help='metric to use for early stopping')
    group_params.add_argument('--patience', default=2, type=int, help='metric to use for early stopping')

    # group for output files
    group_output = argparser_train.add_argument_group("Output files and folders")
    add_out_dir_option(group_output, default='log')
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')

    return


def add_interpret_parser(subparsers):
    """Add interpretation function argument parser
    """
    
    argparser_interpret = subparsers.add_parser("interpret", help="Interpret a TRoNN model")

    # group for input files
    group_input = argparser_interpret.add_argument_group("Input files and folders")
    group_input.add_argument('--data_dir', help='hdf5 file directory')
    group_input.add_argument('--model_dir', help='trained model for interpretation')

    # group for model
    group_model = argparser_interpret.add_argument_group("Model definition")
    group_model.add_argument('--model', nargs='+', help='choose model and provide configs')

    # group for parameters
    group_params = argparser_interpret.add_argument_group("Interpretation hyperparameters")
    group_params.add_argument('--batch_size', default=128, type=int, help='batch size')

    # group for annotation files
    group_data = argparser_interpret.add_argument_group("External data files")
    group_data.add_argument('--annotations', help='json file of external data files')

    # group for output files
    group_output = argparser_interpret.add_argument_group("Output files and folders")
    add_out_dir_option(group_output)
    group_output.add_argument('--prefix', default='tronn', help='prefix to attach onto file names')
    group_output.add_argument('--scratch_dir', help='temporary scratch directory')
    
    return
    
def track_runs():
    """track command and github commit
    """
    return 

def main():
    """Main function for running TRoNN functions"""
    
    print os.path.realpath(__file__) # this works
    #import inspect
    #print inspect.getfile(parse_ar)

    args = parse_args()
    
    # Set up folders, files, etc
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)

    
        
    # important metadata tracking (git, actual command, etc)
    num_restores = len(glob.glob(os.path.join(args.out_dir, 'command')))
    with open(os.path.join(args.out_dir, 'command%d.txt'%num_restores), 'w') as f:
        #git_checkpoint_label = subprocess.check_output(["git", "describe", "--always"])
        #git_checkpoint_label = subprocess.check_output(["git", "-C", "~/git/tronn/", "rev-parse", "HEAD"])
        #f.write(git_checkpoint_label+'\n')
        f.write(' '.join(sys.argv)+'\n')

    subcommand  = args.subcommand_name

    if subcommand == 'train':
        from tronn.learning import run
        run(args)
    elif subcommand == 'interpret':
        from tronn.interpretation import run
        run(args)
        
    return None


if __name__ == '__main__':
    main()
