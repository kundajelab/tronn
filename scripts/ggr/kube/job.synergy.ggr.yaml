apiVersion: batch/v1
kind: Job
metadata:
    name: dk.job.ggr.synergy.basset.point
spec:
    template:
      spec:
        containers:
        - name: train-container
          image: dskim89/tensorflow-genomics
          env:
          - name: MODEL_DIR
            value: "/datasets/models.2018-12-03"
          - name: INFER_DIR
            value: "/datasets/inference.2019-03-12/dmim.point"
          - name: OUT_DIR
            value: "/datasets/inference.2019-03-12/dmim.point"
          - name: MODEL
            value: "basset"
          command: ["bash", "-c"]
          args: ["source ~/.bash_profile && export OUT_DIR=$OUT_DIR/synergy && mkdir -p $OUT_DIR && python /datasets/software/git/tronn/scripts/ggr/kube/run_synergy_cmds.py $MODEL_DIR $MODEL $INFER_DIR $OUT_DIR"]
          resources:
            limits:
              nvidia.com/gpu: 6
          #    cpu: 16
              memory: 128Gi
          #requests:
          #    cpu: 8
          #    memory: 8Gi
          volumeMounts:
          - mountPath: /datasets
            name: datasets
        restartPolicy: Never
        volumes:
        - name: datasets
          flexVolume:
            driver: ceph.rook.io/rook
            fsType: ceph
            options:
             fsName: nautilusfs
             clusterNamespace: rook
             path: /kundajelab
             mountUser: kundajelab
             mountSecret: ceph-fs-secret
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: gpu-type
                  operator: In # Use NotIn for other types
                  values:
                  - "1080Ti"